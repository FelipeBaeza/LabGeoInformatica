{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54643b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point, box\n",
    "from scipy.spatial.distance import cdist\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
    "                             mean_squared_error, r2_score, mean_absolute_error)\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"XGBoost disponible\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost no disponible\")\n",
    "\n",
    "# SHAP para interpretabilidad\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "    print(\"SHAP disponible\")\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"SHAP no disponible\")\n",
    "\n",
    "# Configuración\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Librerías cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad46d27",
   "metadata": {},
   "source": [
    "## 1. Cargar y Preparar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f470ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = '../data/raw/isla_de_pascua'\n",
    "CRS_UTM = 'EPSG:32719'\n",
    "\n",
    "# Cargar datos\n",
    "boundary = gpd.read_file(os.path.join(DATA_PATH, 'isla_de_pascua_boundary.geojson')).to_crs(CRS_UTM)\n",
    "buildings = gpd.read_file(os.path.join(DATA_PATH, 'isla_de_pascua_buildings.geojson')).to_crs(CRS_UTM)\n",
    "amenities = gpd.read_file(os.path.join(DATA_PATH, 'isla_de_pascua_amenities.geojson')).to_crs(CRS_UTM)\n",
    "streets = gpd.read_file(os.path.join(DATA_PATH, 'isla_de_pascua_streets.geojson')).to_crs(CRS_UTM)\n",
    "\n",
    "print(f\"Datos cargados:\")\n",
    "print(f\"   - Edificios: {len(buildings)}\")\n",
    "print(f\"   - Amenidades: {len(amenities)}\")\n",
    "print(f\"   - Calles: {len(streets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66115ae0",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Espacial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7afe17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset de análisis basado en grilla\n",
    "minx, miny, maxx, maxy = boundary.total_bounds\n",
    "cell_size = 200  # metros\n",
    "\n",
    "# Generar grilla\n",
    "grid_cells = []\n",
    "x = minx\n",
    "while x < maxx:\n",
    "    y = miny\n",
    "    while y < maxy:\n",
    "        grid_cells.append(box(x, y, x + cell_size, y + cell_size))\n",
    "        y += cell_size\n",
    "    x += cell_size\n",
    "\n",
    "grid = gpd.GeoDataFrame(geometry=grid_cells, crs=CRS_UTM)\n",
    "grid = grid[grid.intersects(boundary.unary_union)].reset_index(drop=True)\n",
    "grid['cell_id'] = range(len(grid))\n",
    "\n",
    "print(f\"Grilla creada: {len(grid)} celdas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc85feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: Número de edificios\n",
    "grid['n_buildings'] = 0\n",
    "grid['total_building_area'] = 0.0\n",
    "grid['avg_building_area'] = 0.0\n",
    "\n",
    "buildings['area_m2'] = buildings.geometry.area\n",
    "buildings['centroid'] = buildings.geometry.centroid\n",
    "\n",
    "for idx, cell in grid.iterrows():\n",
    "    buildings_in_cell = buildings[buildings['centroid'].within(cell.geometry)]\n",
    "    n = len(buildings_in_cell)\n",
    "    grid.loc[idx, 'n_buildings'] = n\n",
    "    if n > 0:\n",
    "        grid.loc[idx, 'total_building_area'] = buildings_in_cell['area_m2'].sum()\n",
    "        grid.loc[idx, 'avg_building_area'] = buildings_in_cell['area_m2'].mean()\n",
    "\n",
    "print(\"Features de edificios calculados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: Amenidades\n",
    "amenities_point = amenities[amenities.geometry.geom_type == 'Point'].copy()\n",
    "\n",
    "grid['n_amenities'] = 0\n",
    "\n",
    "for idx, cell in grid.iterrows():\n",
    "    n = len(amenities_point[amenities_point.geometry.within(cell.geometry)])\n",
    "    grid.loc[idx, 'n_amenities'] = n\n",
    "\n",
    "# Distancia al centro de la isla (proxy de centralidad)\n",
    "island_center = boundary.geometry.centroid.values[0]\n",
    "grid['centroid'] = grid.geometry.centroid\n",
    "grid['dist_to_center'] = grid['centroid'].distance(island_center)\n",
    "\n",
    "print(\"Features de amenidades y centralidad calculados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba65cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: Densidad de calles (longitud total en la celda)\n",
    "grid['street_length'] = 0.0\n",
    "\n",
    "for idx, cell in grid.iterrows():\n",
    "    streets_in_cell = streets[streets.geometry.intersects(cell.geometry)]\n",
    "    if len(streets_in_cell) > 0:\n",
    "        # Clipear y sumar longitudes\n",
    "        clipped = streets_in_cell.geometry.intersection(cell.geometry)\n",
    "        total_length = clipped.length.sum()\n",
    "        grid.loc[idx, 'street_length'] = total_length\n",
    "\n",
    "print(\"Features de calles calculados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 4: Vecinos (spatial lag)\n",
    "# Calcular número de edificios en celdas vecinas\n",
    "\n",
    "grid['neighbor_buildings'] = 0.0\n",
    "\n",
    "for idx, cell in grid.iterrows():\n",
    "    # Encontrar celdas vecinas (que tocan esta celda)\n",
    "    neighbors = grid[grid.geometry.touches(cell.geometry)]\n",
    "    if len(neighbors) > 0:\n",
    "        grid.loc[idx, 'neighbor_buildings'] = neighbors['n_buildings'].mean()\n",
    "\n",
    "print(\"Features de vecindario calculados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ee3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 5: Coordenadas (para capturar tendencias espaciales)\n",
    "grid['x_coord'] = grid.geometry.centroid.x\n",
    "grid['y_coord'] = grid.geometry.centroid.y\n",
    "\n",
    "# Normalizar coordenadas\n",
    "grid['x_norm'] = (grid['x_coord'] - grid['x_coord'].min()) / (grid['x_coord'].max() - grid['x_coord'].min())\n",
    "grid['y_norm'] = (grid['y_coord'] - grid['y_coord'].min()) / (grid['y_coord'].max() - grid['y_coord'].min())\n",
    "\n",
    "print(\"Coordenadas normalizadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen del dataset\n",
    "feature_cols = ['n_buildings', 'total_building_area', 'avg_building_area', \n",
    "                'n_amenities', 'dist_to_center', 'street_length', \n",
    "                'neighbor_buildings', 'x_norm', 'y_norm']\n",
    "\n",
    "print(\"RESUMEN DE FEATURES\")\n",
    "print(\"=\"*60)\n",
    "print(grid[feature_cols].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar correlaciones\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = grid[feature_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='RdBu_r', center=0, ax=ax, fmt='.2f')\n",
    "ax.set_title('Matriz de Correlación de Features Espaciales', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/13_feature_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea6d35",
   "metadata": {},
   "source": [
    "## 3. Modelo de Clasificación: Zonas de Alta/Baja Densidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear variable objetivo: clasificación de densidad\n",
    "grid['density_class'] = pd.cut(\n",
    "    grid['n_buildings'],\n",
    "    bins=[-1, 0, 5, 20, float('inf')],\n",
    "    labels=['Sin edificios', 'Baja', 'Media', 'Alta']\n",
    ")\n",
    "\n",
    "print(\"Distribución de clases:\")\n",
    "print(grid['density_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f29963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para clasificación\n",
    "# Excluir celdas sin edificios para clasificación binaria\n",
    "grid_with_buildings = grid[grid['n_buildings'] > 0].copy()\n",
    "\n",
    "# Variable binaria: Alta densidad (>10 edificios) vs resto\n",
    "grid_with_buildings['is_high_density'] = (grid_with_buildings['n_buildings'] > 10).astype(int)\n",
    "\n",
    "print(f\"\\nCeldas con edificios: {len(grid_with_buildings)}\")\n",
    "print(f\"Alta densidad: {grid_with_buildings['is_high_density'].sum()}\")\n",
    "print(f\"Baja/media densidad: {(~grid_with_buildings['is_high_density'].astype(bool)).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51388070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir features y target\n",
    "X_cols = ['n_amenities', 'dist_to_center', 'street_length', \n",
    "          'neighbor_buildings', 'x_norm', 'y_norm']\n",
    "\n",
    "X = grid_with_buildings[X_cols].fillna(0)\n",
    "y = grid_with_buildings['is_high_density']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d998ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Entrenar\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predecir\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': acc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   Accuracy: {acc:.4f}\")\n",
    "    print(f\"   CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Random Forest)\n",
    "rf_model = results['Random Forest']['model']\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "importance.plot(kind='barh', x='feature', y='importance', ax=ax, color='steelblue', legend=False)\n",
    "ax.set_xlabel('Importancia')\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_title('Importancia de Features - Random Forest Classifier', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/14_feature_importance_clf.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xgboost_section",
   "metadata": {},
   "source": [
    "## 4.1. Comparación con XGBoost\n",
    "\n",
    "Comparamos Random Forest con XGBoost para regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgboost_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación con XGBoost\n",
    "if XGBOOST_AVAILABLE:\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train_r_scaled, y_train_r)\n",
    "    y_pred_xgb = xgb_model.predict(X_test_r_scaled)\n",
    "    \n",
    "    xgb_rmse = np.sqrt(mean_squared_error(y_test_r, y_pred_xgb))\n",
    "    xgb_r2 = r2_score(y_test_r, y_pred_xgb)\n",
    "    \n",
    "    print(\"XGBoost Regressor:\")\n",
    "    print(f\"   RMSE: {xgb_rmse:.4f}\")\n",
    "    print(f\"   R²: {xgb_r2:.4f}\")\n",
    "    \n",
    "    # Agregar a resultados\n",
    "    reg_results[\"XGBoost\"] = {\n",
    "        \"rmse\": xgb_rmse,\n",
    "        \"r2\": xgb_r2,\n",
    "        \"model\": xgb_model,\n",
    "        \"predictions\": y_pred_xgb\n",
    "    }\n",
    "else:\n",
    "    print(\"XGBoost no disponible - instalar con: pip install xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8db7c",
   "metadata": {},
   "source": [
    "## 4. Modelo de Regresión: Predicción de Densidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión para predecir número de edificios\n",
    "X_reg = grid[X_cols].fillna(0)\n",
    "y_reg = grid['n_buildings']\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler_r = StandardScaler()\n",
    "X_train_r_scaled = scaler_r.fit_transform(X_train_r)\n",
    "X_test_r_scaled = scaler_r.transform(X_test_r)\n",
    "\n",
    "print(f\"Train: {len(X_train_r)} | Test: {len(X_test_r)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde58633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos de regresión\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "reg_results = {}\n",
    "\n",
    "for name, model in reg_models.items():\n",
    "    model.fit(X_train_r_scaled, y_train_r)\n",
    "    y_pred_r = model.predict(X_test_r_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_r, y_pred_r)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_r, y_pred_r)\n",
    "    r2 = r2_score(y_test_r, y_pred_r)\n",
    "    \n",
    "    reg_results[name] = {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'model': model,\n",
    "        'predictions': y_pred_r\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    print(f\"   R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar predicciones vs valores reales\n",
    "best_model_name = max(reg_results, key=lambda x: reg_results[x]['r2'])\n",
    "best_preds = reg_results[best_model_name]['predictions']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test_r, best_preds, alpha=0.5, s=20)\n",
    "ax1.plot([0, y_test_r.max()], [0, y_test_r.max()], 'r--', linewidth=2, label='Línea perfecta')\n",
    "ax1.set_xlabel('Valor Real')\n",
    "ax1.set_ylabel('Predicción')\n",
    "ax1.set_title(f'{best_model_name}\\nR² = {reg_results[best_model_name][\"r2\"]:.4f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Residuales\n",
    "ax2 = axes[1]\n",
    "residuals = y_test_r.values - best_preds\n",
    "ax2.scatter(best_preds, residuals, alpha=0.5, s=20)\n",
    "ax2.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Predicción')\n",
    "ax2.set_ylabel('Residuales')\n",
    "ax2.set_title('Análisis de Residuales')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/15_regression_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "groupkfold_section",
   "metadata": {},
   "source": [
    "## 6.1. Validación Espacial con GroupKFold\n",
    "\n",
    "Usando zonas geográficas como grupos para evitar data leakage espacial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "groupkfold_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear zonas geográficas para GroupKFold\n",
    "grid[\"zone_id\"] = pd.cut(\n",
    "    grid[\"x_norm\"] + grid[\"y_norm\"],\n",
    "    bins=5,\n",
    "    labels=False\n",
    ")\n",
    "\n",
    "X_gkf = grid[X_cols].fillna(0)\n",
    "y_gkf = grid[\"n_buildings\"]\n",
    "groups_gkf = grid[\"zone_id\"]\n",
    "\n",
    "# GroupKFold Cross-Validation\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "rf_gkf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "gkf_scores = []\n",
    "print(\"GroupKFold Spatial Cross-Validation:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_gkf, y_gkf, groups_gkf)):\n",
    "    X_tr = X_gkf.iloc[train_idx]\n",
    "    X_te = X_gkf.iloc[test_idx]\n",
    "    y_tr = y_gkf.iloc[train_idx]\n",
    "    y_te = y_gkf.iloc[test_idx]\n",
    "    \n",
    "    scaler_gkf = StandardScaler()\n",
    "    X_tr_sc = scaler_gkf.fit_transform(X_tr)\n",
    "    X_te_sc = scaler_gkf.transform(X_te)\n",
    "    \n",
    "    rf_gkf.fit(X_tr_sc, y_tr)\n",
    "    y_pred_gkf = rf_gkf.predict(X_te_sc)\n",
    "    \n",
    "    r2_fold = r2_score(y_te, y_pred_gkf)\n",
    "    gkf_scores.append(r2_fold)\n",
    "    print(f\"Fold {fold+1}: R² = {r2_fold:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Mean R²: {np.mean(gkf_scores):.4f} (+/- {np.std(gkf_scores)*2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a8a16",
   "metadata": {},
   "source": [
    "## 5. Clustering Espacial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24bdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering\n",
    "X_cluster = grid[['x_norm', 'y_norm', 'n_buildings', 'n_amenities', 'street_length']].fillna(0)\n",
    "X_cluster_scaled = StandardScaler().fit_transform(X_cluster)\n",
    "\n",
    "# Encontrar número óptimo de clusters (Elbow method)\n",
    "inertias = []\n",
    "K_range = range(2, 10)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Gráfico del codo\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(K_range, inertias, 'bo-')\n",
    "ax.set_xlabel('Número de Clusters (K)')\n",
    "ax.set_ylabel('Inercia')\n",
    "ax.set_title('Método del Codo - K-Means')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325391b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar K-Means con K óptimo\n",
    "k_optimal = 4\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)\n",
    "grid['cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "print(f\"Distribución de clusters:\")\n",
    "print(grid['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shap_section",
   "metadata": {},
   "source": [
    "## 7.1. Interpretabilidad con SHAP Values\n",
    "\n",
    "Análisis de la importancia de features usando SHAP (SHapley Additive exPlanations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shap_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretabilidad con SHAP\n",
    "if SHAP_AVAILABLE:\n",
    "    print(\"Calculando SHAP values...\")\n",
    "    \n",
    "    # Usar el modelo Random Forest entrenado\n",
    "    rf_for_shap = reg_results[\"Random Forest Regressor\"][\"model\"]\n",
    "    \n",
    "    # Crear explainer\n",
    "    explainer = shap.TreeExplainer(rf_for_shap)\n",
    "    \n",
    "    # Calcular SHAP values (usar muestra para velocidad)\n",
    "    X_sample = X_reg.sample(min(100, len(X_reg)), random_state=42)\n",
    "    X_sample_scaled = scaler_r.transform(X_sample)\n",
    "    shap_values = explainer.shap_values(X_sample_scaled)\n",
    "    \n",
    "    # Summary plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X_sample, feature_names=X_cols, show=False)\n",
    "    plt.title(\"SHAP Summary Plot - Random Forest\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../outputs/18_shap_summary.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Bar plot de importancia media\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X_sample, feature_names=X_cols, plot_type=\"bar\", show=False)\n",
    "    plt.title(\"SHAP Feature Importance\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../outputs/19_shap_importance.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nSHAP analysis completado!\")\n",
    "else:\n",
    "    print(\"SHAP no disponible - instalar con: pip install shap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baabd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa de clusters\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Límite\n",
    "boundary.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# Clusters\n",
    "colors = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00']\n",
    "for cluster_id in range(k_optimal):\n",
    "    subset = grid[grid['cluster'] == cluster_id]\n",
    "    subset.plot(ax=ax, color=colors[cluster_id], edgecolor='gray', \n",
    "                linewidth=0.5, alpha=0.7, label=f'Cluster {cluster_id}')\n",
    "\n",
    "ax.legend(loc='lower right', title='Cluster')\n",
    "ax.set_title('Clustering Espacial - K-Means\\nIsla de Pascua', fontsize=14, fontweight='bold')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/16_spatial_clustering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d123f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfil de clusters\n",
    "cluster_profile = grid.groupby('cluster')[['n_buildings', 'n_amenities', 'street_length', 'dist_to_center']].mean()\n",
    "cluster_profile.columns = ['Edificios (prom)', 'Amenidades (prom)', 'Long. Calles (m)', 'Dist. Centro (m)']\n",
    "\n",
    "print(\"PERFIL DE CLUSTERS\")\n",
    "print(\"=\"*60)\n",
    "print(cluster_profile.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00804b",
   "metadata": {},
   "source": [
    "## 6. Validación Espacial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feec54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Cross-Validation usando los clusters como folds\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "X_spatial = grid[X_cols].fillna(0)\n",
    "y_spatial = grid['n_buildings']\n",
    "groups = grid['cluster']\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "spatial_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(logo.split(X_spatial, y_spatial, groups)):\n",
    "    X_tr, X_te = X_spatial.iloc[train_idx], X_spatial.iloc[test_idx]\n",
    "    y_tr, y_te = y_spatial.iloc[train_idx], y_spatial.iloc[test_idx]\n",
    "    \n",
    "    scaler_sp = StandardScaler()\n",
    "    X_tr_scaled = scaler_sp.fit_transform(X_tr)\n",
    "    X_te_scaled = scaler_sp.transform(X_te)\n",
    "    \n",
    "    rf_reg.fit(X_tr_scaled, y_tr)\n",
    "    y_pred_sp = rf_reg.predict(X_te_scaled)\n",
    "    \n",
    "    r2_sp = r2_score(y_te, y_pred_sp)\n",
    "    spatial_scores.append(r2_sp)\n",
    "    print(f\"Fold {fold} (Cluster {fold} como test): R² = {r2_sp:.4f}\")\n",
    "\n",
    "print(f\"\\nSpatial CV Score: {np.mean(spatial_scores):.4f} (+/- {np.std(spatial_scores)*2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfe3f6",
   "metadata": {},
   "source": [
    "## 7. Mapa de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a88595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir para toda la grilla\n",
    "best_reg_model = reg_results['Random Forest Regressor']['model']\n",
    "X_all_scaled = scaler_r.transform(X_reg)\n",
    "grid['predicted_buildings'] = best_reg_model.predict(X_all_scaled)\n",
    "grid['prediction_error'] = grid['n_buildings'] - grid['predicted_buildings']\n",
    "\n",
    "# Mapa de predicciones\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Real\n",
    "ax1 = axes[0]\n",
    "boundary.plot(ax=ax1, facecolor='none', edgecolor='black', linewidth=2)\n",
    "grid.plot(column='n_buildings', ax=ax1, cmap='YlOrRd', legend=True,\n",
    "          legend_kwds={'label': 'N° Edificios'})\n",
    "ax1.set_title('Valores Reales', fontsize=12, fontweight='bold')\n",
    "ax1.set_axis_off()\n",
    "\n",
    "# Predicho\n",
    "ax2 = axes[1]\n",
    "boundary.plot(ax=ax2, facecolor='none', edgecolor='black', linewidth=2)\n",
    "grid.plot(column='predicted_buildings', ax=ax2, cmap='YlOrRd', legend=True,\n",
    "          legend_kwds={'label': 'N° Predicho'})\n",
    "ax2.set_title('Predicciones', fontsize=12, fontweight='bold')\n",
    "ax2.set_axis_off()\n",
    "\n",
    "# Error\n",
    "ax3 = axes[2]\n",
    "boundary.plot(ax=ax3, facecolor='none', edgecolor='black', linewidth=2)\n",
    "grid.plot(column='prediction_error', ax=ax3, cmap='RdBu_r', legend=True,\n",
    "          legend_kwds={'label': 'Error'})\n",
    "ax3.set_title('Error (Real - Predicho)', fontsize=12, fontweight='bold')\n",
    "ax3.set_axis_off()\n",
    "\n",
    "plt.suptitle('Comparación: Valores Reales vs Predicciones\\nRandom Forest Regressor', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/17_prediction_maps.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee657a1",
   "metadata": {},
   "source": [
    "## 8. Guardar Modelos y Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar modelos\n",
    "os.makedirs('../outputs/models', exist_ok=True)\n",
    "\n",
    "joblib.dump(best_reg_model, '../outputs/models/rf_regressor.joblib')\n",
    "joblib.dump(scaler_r, '../outputs/models/scaler.joblib')\n",
    "joblib.dump(kmeans, '../outputs/models/kmeans_clustering.joblib')\n",
    "\n",
    "# Guardar grid con predicciones\n",
    "grid.drop(columns=['centroid'], errors='ignore').to_file(\n",
    "    '../outputs/grid_with_predictions.geojson', driver='GeoJSON'\n",
    ")\n",
    "\n",
    "print(\"Modelos y resultados guardados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ae6d2",
   "metadata": {},
   "source": [
    "## 9. Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN DE MACHINE LEARNING ESPACIAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFEATURES CREADOS:\")\n",
    "for col in X_cols:\n",
    "    print(f\"   • {col}\")\n",
    "\n",
    "print(\"\\nCLASIFICACIÓN (Alta Densidad vs Resto):\")\n",
    "for name, res in results.items():\n",
    "    print(f\"   • {name}: Accuracy = {res['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nREGRESIÓN (Predicción N° Edificios):\")\n",
    "for name, res in reg_results.items():\n",
    "    print(f\"   • {name}: R² = {res['r2']:.4f}, RMSE = {res['rmse']:.2f}\")\n",
    "\n",
    "print(\"\\nCLUSTERING:\")\n",
    "print(f\"   • K-Means con K={k_optimal} clusters\")\n",
    "for cluster_id in range(k_optimal):\n",
    "    n = (grid['cluster'] == cluster_id).sum()\n",
    "    print(f\"   • Cluster {cluster_id}: {n} celdas\")\n",
    "\n",
    "print(\"\\nVALIDACIÓN ESPACIAL:\")\n",
    "print(f\"   • Leave-One-Cluster-Out: R² = {np.mean(spatial_scores):.4f} (+/- {np.std(spatial_scores)*2:.4f})\")\n",
    "\n",
    "print(\"\\nARCHIVOS GENERADOS:\")\n",
    "print(\"   • outputs/13_feature_correlation.png\")\n",
    "print(\"   • outputs/14_feature_importance_clf.png\")\n",
    "print(\"   • outputs/15_regression_results.png\")\n",
    "print(\"   • outputs/16_spatial_clustering.png\")\n",
    "print(\"   • outputs/17_prediction_maps.png\")\n",
    "print(\"   • outputs/models/rf_regressor.joblib\")\n",
    "print(\"   • outputs/models/scaler.joblib\")\n",
    "print(\"   • outputs/models/kmeans_clustering.joblib\")\n",
    "print(\"   • outputs/grid_with_predictions.geojson\")\n",
    "\n",
    "print(\"\\nFase 3 completada!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
